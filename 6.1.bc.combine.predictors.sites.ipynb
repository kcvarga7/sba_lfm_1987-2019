{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5e6132-75c4-4472-97cd-9e71165d9490",
   "metadata": {},
   "source": [
    "# Combine WRF and Landsat predictors at fuel specific LFM observation sites <br> for entire temporal domain\n",
    "Last updated: Kevin Varga, 11/27/2024\n",
    "\n",
    "**Inputs:**\n",
    "* Predictor variable netcdf files\n",
    "\n",
    "**Outputs:**\n",
    "* Fuel specific csv files with observation site and full date range as pandas index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2d3a1a-6faa-4641-9679-7f8d3edb6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8ac83f-8db3-421d-9b06-d77ddb180fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "obs_path = '/home/sbarc/students/varga/nasa/ch1/data/lfm_obs/'\n",
    "# Predictors are on SMS temporal resolution\n",
    "predictor_path = '/home/sbarc/students/varga/nasa/ch1/data/predictors/'\n",
    "output_path = '/home/sbarc/students/varga/nasa/ch1/data/bias_correction/site_predictors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ebb5bf-040d-4c9f-aee7-52f6cabc9703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in LFM observations and clean up\n",
    "obs_df = pd.read_csv(obs_path + 'lfm_crop.csv')\n",
    "obs_df.drop(columns=['slope', 'aspect', 'elevation', 'gacc', 'category'], inplace=True)\n",
    "obs_df['date'] = pd.to_datetime(obs_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd07d8cb-5c8a-4426-82f0-79844d7a6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column labels for combined predictor dataframe\n",
    "col_labels = ['latitude', 'longitude', 'cwd90sum', 'daylength', 'nirv', 'precip30sum', \n",
    "              'precip90sum', 'rad150mean','rh150mean', 'somo7mean', 'temp90mean']\n",
    "\n",
    "# Create list of predictor names in the same order that model was created\n",
    "predictors = ['cwd90sum', 'daylength', 'nirv', 'precip30sum', \n",
    "              'precip90sum', 'rad150mean','rh150mean', 'somo7mean', 'temp90mean']\n",
    "\n",
    "# Get unique fuel type values only if there are more than 500\n",
    "fuels = obs_df['fuel'].value_counts()\n",
    "fuels = fuels[fuels >= 500].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235d6d83-b63b-4f16-b204-bcf14f142249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date range that aligns with predictor date range\n",
    "start_date = pd.to_datetime('12/01/1987')\n",
    "end_date = pd.to_datetime('06/30/2019')\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='SMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01760f5e-f482-470b-b1bb-5f0cd1ac0f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chamise has 0 nan values\n",
      "chamise_old_growth has 0 nan values\n",
      "sage_black has 0 nan values\n",
      "ceanothus_bigpod has 0 nan values\n",
      "CPU times: user 9.65 s, sys: 16.3 s, total: 25.9 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fuel_type in fuels:\n",
    "    # Subset observations from fuel type\n",
    "    fuel_obs_df = obs_df.loc[obs_df['fuel'] == fuel_type]\n",
    "    fuel_obs_df.reset_index(drop=True, inplace=True)\n",
    "    # Determine observation site names\n",
    "    sites = fuel_obs_df['site'].drop_duplicates()\n",
    "    # Create multi index of site name and observation dates\n",
    "    fuel_obs_df.set_index(['site', 'date'], inplace=True)\n",
    "    \n",
    "    # Create fuel specific dataframe with all sites and dates as multi index\n",
    "    all_dates_index = pd.MultiIndex.from_product([sites, all_dates], names=['site', 'date'])\n",
    "    all_dates_df = pd.DataFrame(index = all_dates_index, columns = col_labels)\n",
    "    \n",
    "    # Input observation site latitude and longitude\n",
    "    for site_name in sites:\n",
    "        all_dates_df.loc[site_name, 'latitude'][:] = fuel_obs_df.loc[site_name, 'latitude'][0]\n",
    "        all_dates_df.loc[site_name, 'longitude'][:] = fuel_obs_df.loc[site_name, 'longitude'][0]\n",
    "    \n",
    "    for predictor_name in predictors:\n",
    "        # Open predictor variable data array covering entire spatiotemporal domain\n",
    "        pred_da = xr.open_dataarray(predictor_path + predictor_name + '.nc')\n",
    "        # Subset predictor variable to date range\n",
    "        pred_da = pred_da.sel(time = slice(start_date,end_date))\n",
    "        \n",
    "        for i, site_name in enumerate(sites):\n",
    "            # Interpolate predictor values to observation site location\n",
    "            site_pred_da = pred_da.interp(latitude = all_dates_df.loc[site_name, 'latitude'][0], \n",
    "                                          longitude = all_dates_df.loc[site_name, 'longitude'][0])\n",
    "            site_pred_da = site_pred_da.drop_vars(['latitude','longitude'])\n",
    "            site_pred_values = site_pred_da.to_numpy()\n",
    "\n",
    "            # Combine predictor variable values at each site\n",
    "            if i == 0:\n",
    "                all_pred_values = site_pred_values\n",
    "            else:\n",
    "                all_pred_values = np.concatenate([all_pred_values, site_pred_values])\n",
    "        \n",
    "        # Save predictor variable values to combined dataframe\n",
    "        all_dates_df.loc[:, predictor_name] = all_pred_values\n",
    "\n",
    "    # Save fuel specific dataframe with all predictor variables for each site\n",
    "    all_dates_df.to_csv(output_path + fuel_type + '.csv', index_label=['site','date'])\n",
    "    # Verify that there are not any NaN values, which will mess the model up\n",
    "    #nan_test = len(all_dates_df) - len(all_dates_df.dropna())\n",
    "    #print(fuel_type + ' has ' + str(nan_test) + ' nan values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyclivac)",
   "language": "python",
   "name": "pyclivac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
