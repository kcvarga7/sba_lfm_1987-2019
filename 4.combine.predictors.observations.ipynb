{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baf4127-e60a-4687-bee4-adca262a5b02",
   "metadata": {},
   "source": [
    "# Combine WRF and Landsat predictors into site and fuel specific dataframes\n",
    "Last updated: Kevin Varga, 11/21/2024\n",
    "\n",
    "**Inputs:**\n",
    "* National Fuel Moisture Database LFM observations\n",
    "* WRF predictor variable netcdf files\n",
    "* Landsat NIRv predictor variable netcdf file\n",
    "\n",
    "**Outputs:**\n",
    "* Fuel type specific data frames with all predictor variables aligned with all LFM observation times and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2d3a1a-6faa-4641-9679-7f8d3edb6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8ac83f-8db3-421d-9b06-d77ddb180fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path to predictor variables calculated on a daily basis\n",
    "predictor_path = '/home/sbarc/students/varga/nasa/ch1/data/predictors/daily/'\n",
    "obs_path = '/home/sbarc/students/varga/nasa/ch1/data/lfm_obs/'\n",
    "output_path = '/home/sbarc/students/varga/nasa/ch1/data/site_predictors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ebb5bf-040d-4c9f-aee7-52f6cabc9703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in LFM observations and clean up\n",
    "obs_df = pd.read_csv(obs_path + 'lfm_crop.csv')\n",
    "obs_df.drop(columns=['slope', 'aspect', 'elevation', 'gacc', 'category'], inplace=True)\n",
    "obs_df['date'] = pd.to_datetime(obs_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd07d8cb-5c8a-4426-82f0-79844d7a6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of predictor variable names\n",
    "predictors = ['cwd90sum', 'daylength', 'nirv', 'precip30sum', \n",
    "              'precip90sum', 'rad150mean','rh150mean', 'somo7mean', 'temp90mean']\n",
    "\n",
    "# Get unique fuel type values only if there are more than 500 (our random forest model threshold)\n",
    "fuels = obs_df['fuel'].value_counts()\n",
    "fuels = fuels[fuels >= 500].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01760f5e-f482-470b-b1bb-5f0cd1ac0f51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 59 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through each fuel type\n",
    "for fuel_type in fuels:\n",
    "    # Subset fuel type and identify individual LFM sampling sites for each fuel\n",
    "    fuel_obs_df = obs_df.loc[obs_df['fuel'] == fuel_type].copy()\n",
    "    fuel_obs_df = fuel_obs_df.reset_index(drop=True)\n",
    "    sites = fuel_obs_df['site'].drop_duplicates()\n",
    "    fuel_obs_df = fuel_obs_df.set_index(['site', 'date'])\n",
    "\n",
    "    # Loop through each predictor variable\n",
    "    for predictor_name in predictors:\n",
    "        # Open predictor data array covering entire domain\n",
    "        pred_da = xr.open_dataarray(predictor_path + predictor_name + '_daily.nc')\n",
    "\n",
    "        # Loop through each LFM sampling site\n",
    "        for i, site_name in enumerate(sites):\n",
    "            # Subset site\n",
    "            site_fuel_obs_df = fuel_obs_df.loc[site_name, :]\n",
    "            # Extract predictor variable data at site location and LFM sampling times\n",
    "            site_pred_da = pred_da.interp(time = site_fuel_obs_df.index,\n",
    "                                          latitude = site_fuel_obs_df['latitude'][0],\n",
    "                                          longitude = site_fuel_obs_df['longitude'][0])\n",
    "\n",
    "            if predictor_name == 'nirv':\n",
    "                # NIRv not saved on daily temporal resolution, only saved at SMS resolution\n",
    "                # Interpolate nan values up to a limit of 40 days for NIRv due to sporadic missing values\n",
    "                site_pred_da = site_pred_da.interpolate_na(dim='time', method='quadratic', \n",
    "                                                           max_gap=pd.Timedelta(40, 'd'), fill_value='extrapolate')\n",
    "                # Drop lat/lon and convert to numpy\n",
    "                site_pred_da = site_pred_da.drop_vars(['latitude','longitude'])\n",
    "                site_pred_values = site_pred_da.to_numpy()\n",
    "\n",
    "            else:\n",
    "                # Drop lat/lon and convert to numpy\n",
    "                site_pred_da = site_pred_da.drop_vars(['latitude','longitude'])\n",
    "                site_pred_values = site_pred_da.to_numpy()\n",
    "\n",
    "            if i == 0:\n",
    "                # Save to new array if on the first LFM sampling site of a fuel and predictor\n",
    "                all_pred_values = site_pred_values\n",
    "\n",
    "            else:\n",
    "                # Concatenate each LFM sampling site for inidividual fuels and predictors\n",
    "                all_pred_values = np.concatenate([all_pred_values, site_pred_values])\n",
    "\n",
    "        # Save all predictor values in the fuel specific obervation dataframe\n",
    "        fuel_obs_df.loc[:, predictor_name] = all_pred_values\n",
    "        \n",
    "    # Save each fuel_specific dataframe with all predictor variables at every sampling site\n",
    "    fuel_obs_df.to_csv(output_path + fuel_type + '.csv', index_label=['site','date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8ee05-8b24-4a10-9c6c-539d028f17d4",
   "metadata": {},
   "source": [
    "### Additional code for testing NIRv interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3c865b-2375-4404-9607-578db5e5a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open NIRv data array\n",
    "pred_da = xr.open_dataarray(predictor_path + 'nirv' + '_daily.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344fc8cc-6d9c-41df-b8b8-ce0858efca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the chamise LFM sampling sites\n",
    "fuel_obs_df = obs_df.loc[obs_df['fuel'] == 'chamise']\n",
    "fuel_obs_df.reset_index(drop=True, inplace=True)\n",
    "sites = fuel_obs_df['site'].drop_duplicates()\n",
    "# Set site and date as multiindex\n",
    "fuel_obs_df.set_index(['site', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002a6940-d3bd-46eb-8218-f1bec9206394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               prenan premin premax postnan postmin postmax\n",
      "site                                                                       \n",
      "bitter_canyon_castaic               1   0.02   0.11       0    0.02    0.11\n",
      "cachuma                             0   0.04   0.13       0    0.04    0.13\n",
      "circle_x_malibu                     0   0.05   0.13       0    0.05    0.13\n",
      "clark_motorway_malibu               0   0.04   0.16       0    0.04    0.16\n",
      "gifford                             1   0.04   0.12       0    0.04    0.12\n",
      "harris_grade                        0   0.06   0.12       0    0.06    0.12\n",
      "irish_hills                         1   0.06   0.14       0    0.06    0.14\n",
      "laguna_ridge_casitas                1   0.05   0.26       0    0.05    0.26\n",
      "lopez_lake                          1   0.05   0.16       0    0.05    0.16\n",
      "los_alamos                          1   0.03   0.08       0    0.03    0.08\n",
      "los_robles_thousand_oaks            1   0.05   0.12       0    0.05    0.12\n",
      "oak_flat                            2   0.06   0.15       0    0.06    0.15\n",
      "parkhill                            1   0.05   0.12       0    0.05    0.12\n",
      "pico_canyon                         0   0.03   0.14       0    0.03    0.14\n",
      "refugio                             0   0.07   0.16       0    0.07    0.16\n",
      "reyes_creek                         2   0.04    0.1       0    0.04    0.12\n",
      "rose_valley                         2   0.04   0.11       0    0.04    0.12\n",
      "san_marcos                          1   0.08   0.16       0    0.08    0.16\n",
      "schueren_road_malibu                1   0.03   0.18       0    0.03    0.18\n",
      "sisar_canyon_upper_ojai_valley      0   0.07   0.15       0    0.07    0.15\n",
      "stunt_road_calabasas                1   0.05   0.15       0    0.05    0.15\n",
      "tapo_canyon_simi_valley             1   0.04   0.16       0    0.04    0.16\n",
      "templin_highway                     1   0.03   0.12       0    0.03    0.12\n",
      "tepusquet                           0   0.05   0.15       0    0.05    0.15\n",
      "trippet_ranch_topanga               1   0.06   0.17       0    0.06    0.17\n",
      "upper_oso                           1   0.03   0.12       0    0.03    0.13\n",
      "west_gaviota                        0   0.08   0.19       0    0.08    0.19\n",
      "woolsey_canyon                      0   0.04   0.13       0    0.04    0.13\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe to store stats\n",
    "qstats = pd.DataFrame(index = sites, columns = ['prenan','premin','premax','postnan','postmin','postmax'])\n",
    "\n",
    "for i, site_name in enumerate(sites):\n",
    "    # Subset site\n",
    "    site_fuel_obs_df = fuel_obs_df.loc[site_name, :]\n",
    "    # Extract predictor variable data at site location and LFM sampling times\n",
    "    site_pred_da = pred_da.interp(time = site_fuel_obs_df.index,\n",
    "                                  latitude = site_fuel_obs_df['latitude'][0], \n",
    "                                  longitude = site_fuel_obs_df['longitude'][0])\n",
    "    # Record how many nan values there were before data filling interpolation, as well as the min/max values\n",
    "    qstats.loc[site_name, 'prenan'] = (len(site_pred_da) - site_pred_da.count().to_numpy())\n",
    "    qstats.loc[site_name, 'premin'] = np.round(site_pred_da.min().values, 2)\n",
    "    qstats.loc[site_name, 'premax'] = np.round(site_pred_da.max().values, 2)\n",
    "    \n",
    "    # Interpolate nan values up to a limit of 40 days\n",
    "    site_pred_da = site_pred_da.interpolate_na(dim='time', method='quadratic', max_gap=pd.Timedelta(40, 'd'), fill_value='extrapolate')\n",
    "    # Record how many nan values there were after interpolation, as well as the min/max values\n",
    "    qstats.loc[site_name, 'postnan'] = (len(site_pred_da) - site_pred_da.count().to_numpy())\n",
    "    qstats.loc[site_name, 'postmin'] = np.round(site_pred_da.min().values, 2)\n",
    "    qstats.loc[site_name, 'postmax'] = np.round(site_pred_da.max().values, 2)\n",
    "\n",
    "print(qstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7f07b-6cba-4597-ae3a-387ff87d02e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyclivac)",
   "language": "python",
   "name": "pyclivac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
