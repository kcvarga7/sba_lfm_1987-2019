{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and save WRF predictor variables over entire spatiotemporal domain\n",
    "Last updated: Kevin Varga, 05/20/2024\n",
    "\n",
    "**Inputs:**\n",
    "* Pre-processed WRF files of daily temperature, precipitation, relative humidity, and wind\n",
    "* Pre-processed WRF files of shortwave and net radiation, soil moisture, pressure, and actual evapotranspiration <br>\n",
    "\n",
    "**Outputs:**\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/temp90mean.nc - mean 90 day temperature <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/precip30sum.nc - sum 30 day precipitation <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/precip90sum.nc - sum 90 day precipitation <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/rh150mean.nc - mean 150 day relative humidity <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/rad150mean.nc - mean 150 day incoming radiation <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/somo7mean.nc - mean 7 day soil moisture <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/daylength.nc - length of the day <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/eto90sum.nc - sum 90 day reference evapotranspiration <br>\n",
    "* /home/sbarc/students/varga/nasa/ch1/data/predictors/cwd90sum.nc - sum 90 day climatic water deficit <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path in for wrf files that were previously processed by Charles Jones, UCSB\n",
    "# includes daily mean temp, rh, precip, and wind, saved in yearly outputs\n",
    "wrf_ch_path = '/home/sbarc/wrf/wrf401/sbareg/sbcwrf/'\n",
    "\n",
    "# path in for wrf files that were previously processed by kevin varga\n",
    "# includes aet, ea, es, netrad, psfc, smois, and swdnb\n",
    "wrf_vars_path = '/home/sbarc/students/varga/nasa/ch1/data/wrf/vars/'\n",
    "\n",
    "# path to save predictor outputs\n",
    "wrf_out = '/home/sbarc/students/varga/nasa/ch1/data/predictors/'\n",
    "wrf_out_daily = '/home/sbarc/students/varga/nasa/ch1/data/predictors/daily/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_in = 'land_mask.nc'\n",
    "# open data array containing 1 for land and 0 for water\n",
    "land_mask = xr.open_dataarray(wrf_vars_path + file_in)\n",
    "# extract lat/lon values\n",
    "wrf_lats = land_mask['XLAT'].values[:,0]\n",
    "wrf_lons = land_mask['XLONG'].values[0,:]\n",
    "# assign lat/lon coordinates as spatial dimensions and clean up\n",
    "land_mask['south_north'] = wrf_lats\n",
    "land_mask['west_east'] = wrf_lons\n",
    "land_mask = land_mask.rename({'south_north':'latitude', 'west_east':'longitude'})\n",
    "ex_coords = ['XLAT','XLONG','XTIME']\n",
    "land_mask = land_mask.drop(ex_coords)\n",
    "\n",
    "# create mask for land\n",
    "land_mask = (land_mask >=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temp90mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 30.2 s, total: 1min 54s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_in = 'dly_airt/'\n",
    "file_in = '*mean*.nc'\n",
    "file_out = 'temp90mean'\n",
    "\n",
    "# create list of all mean temperature wrf files\n",
    "wrf_list = sorted(list(Path(wrf_ch_path + dir_in).glob(file_in)))\n",
    "\n",
    "# open all files into a dataset\n",
    "da = xr.open_mfdataset(wrf_list)\n",
    "\n",
    "# assign lat/lon coordinates as spatial dimensions and clean up\n",
    "da['south_north'] = wrf_lats\n",
    "da['west_east'] = wrf_lons\n",
    "da = da.rename({'south_north':'latitude', 'west_east':'longitude', 'times':'time'})\n",
    "ex_coords = ['XLAT','XLONG']\n",
    "da = da.drop(ex_coords)\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da['airtmean'].where(land_mask, drop=True)\n",
    "\n",
    "# load variable out of dask array to remove 2017-08-28 bad values\n",
    "da = da.load()\n",
    "da.loc['2017-08-28'] = np.nan\n",
    "\n",
    "# create temp array for later use in eto calculation\n",
    "temp_array = da.data\n",
    "\n",
    "# calculate 90-day moving averages\n",
    "da = da.rolling(time=90, min_periods=86).mean()\n",
    "\n",
    "# save daily output for use in model validation\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out_daily + file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th for dataset creation\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output for dataset creation\n",
    "da.to_netcdf(wrf_out + file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## precip30sum and precip90sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 1min 1s, total: 5min 11s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_in = 'dly_prec/'\n",
    "file_in = '*.nc'\n",
    "precip30_file_out = 'precip30sum'\n",
    "precip90_file_out = 'precip90sum'\n",
    "\n",
    "# create list of all mean temperature wrf files\n",
    "wrf_list = sorted(list(Path(wrf_ch_path + dir_in).glob(file_in)))\n",
    "\n",
    "# open all files into a dataset\n",
    "da = xr.open_mfdataset(wrf_list)\n",
    "\n",
    "# assign lat/lon coordinates as spatial dimensions and clean up\n",
    "da['south_north'] = wrf_lats\n",
    "da['west_east'] = wrf_lons\n",
    "da = da.rename({'south_north':'latitude', 'west_east':'longitude', 'times':'time'})\n",
    "ex_coords = ['XLAT','XLONG']\n",
    "da = da.drop(ex_coords)\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da['precsum'].where(land_mask, drop=True)\n",
    "\n",
    "# load variable out of dask array to remove 2017-08-28 bad data, found through plotting\n",
    "da = da.load()\n",
    "da.loc['2017-08-28'] = np.nan\n",
    "\n",
    "# calculate daily rainfall from accumulated rainfall\n",
    "array = np.empty([len(da['time']),len(da['latitude']),len(da['longitude'])])\n",
    "for i in range(len(da['time'])):\n",
    "    if da['time.month'][i].values == 7 and da['time.day'][i].values == 1:\n",
    "        array[i,:,:] = da[i,:,:]\n",
    "    else:\n",
    "        array[i,:,:] = da[i,:,:] - da[i-1,:,:]\n",
    "\n",
    "da.data = array\n",
    "\n",
    "# calculate 30-day accumulations\n",
    "da30 = da.rolling(time=30, min_periods=28).sum()\n",
    "\n",
    "# calculate 90-day accumulations\n",
    "da90 = da.rolling(time=90, min_periods=86).sum()\n",
    "\n",
    "# save daily output\n",
    "da30.name = precip30_file_out\n",
    "da90.name = precip90_file_out\n",
    "da30.to_netcdf(wrf_out_daily + precip30_file_out + '_daily.nc')\n",
    "da90.to_netcdf(wrf_out_daily + precip90_file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da30 = da30.resample(time='SMS').nearest()\n",
    "da90 = da90.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output\n",
    "da30.to_netcdf(wrf_out + precip30_file_out + '.nc')\n",
    "da90.to_netcdf(wrf_out + precip90_file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rh150mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 43 s, total: 1min 59s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_in = 'dly_relhum/'\n",
    "file_in = '*mean*.nc'\n",
    "file_out = 'rh150mean'\n",
    "\n",
    "# create list of all mean temperature wrf files\n",
    "wrf_list = sorted(list(Path(wrf_ch_path + dir_in).glob(file_in)))\n",
    "\n",
    "# open all files into a dataset\n",
    "da = xr.open_mfdataset(wrf_list)\n",
    "\n",
    "# assign lat/lon coordinates as spatial dimensions and clean up\n",
    "da['south_north'] = wrf_lats\n",
    "da['west_east'] = wrf_lons\n",
    "da = da.rename({'south_north':'latitude', 'west_east':'longitude', 'times':'time'})\n",
    "ex_coords = ['XLAT','XLONG']\n",
    "da = da.drop(ex_coords)\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da['rhmean'].where(land_mask, drop=True)\n",
    "\n",
    "# load variable out of dask array to remove 2017-08-28 bad values\n",
    "da = da.load()\n",
    "da.loc['2017-08-28'] = np.nan\n",
    "\n",
    "# calculate 150-day moving averages\n",
    "da = da.rolling(time=150, min_periods=142).mean()\n",
    "\n",
    "# save daily output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out_daily + file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output\n",
    "da.to_netcdf(wrf_out + file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rad150mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_in = 'swdnb.nc'\n",
    "file_out = 'rad150mean'\n",
    "\n",
    "# read in shortwave radiation file covering all years\n",
    "da = xr.open_dataarray(wrf_vars_path + file_in)\n",
    "\n",
    "# resample to fill missing days with nan\n",
    "da = da.resample(time='D').ffill(0)\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "\n",
    "# calculate 150-day moving averages\n",
    "da = da.rolling(time=150, min_periods=142).mean()\n",
    "\n",
    "# save daily output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out_daily + file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output\n",
    "da.to_netcdf(wrf_out + file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## somo7mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 35s, sys: 1min 59s, total: 8min 35s\n",
      "Wall time: 5min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_in = 'smois.nc'\n",
    "file_out = 'somo7mean'\n",
    "\n",
    "# read in shortwave radiation file covering all years\n",
    "da = xr.open_dataarray(wrf_vars_path + file_in)\n",
    "\n",
    "# resample and interpolate to fill sporadic missing days\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "\n",
    "# calculate 7-day moving averages\n",
    "da = da.rolling(time=7).mean()\n",
    "\n",
    "# save daily output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out_daily + file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out + file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## daylength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day length function from:\n",
    "# https://gist.github.com/anttilipp/ed3ab35258c7636d87de6499475301ce\n",
    "\n",
    "def daylength(dayOfYear, lat):\n",
    "    \"\"\"Computes the length of the day (the time between sunrise and\n",
    "    sunset) given the day of the year and latitude of the location.\n",
    "    Function uses the Brock model for the computations.\n",
    "    For more information see, for example,\n",
    "    Forsythe et al., \"A model comparison for daylength as a\n",
    "    function of latitude and day of year\", Ecological Modelling,\n",
    "    1995.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dayOfYear : int\n",
    "        The day of the year. 1 corresponds to 1st of January\n",
    "        and 365 to 31st December (on a non-leap year).\n",
    "    lat : float\n",
    "        Latitude of the location in degrees. Positive values\n",
    "        for north and negative for south.\n",
    "    Returns\n",
    "    -------\n",
    "    d : float\n",
    "        Daylength in hours.\n",
    "    \"\"\"\n",
    "    latInRad = np.deg2rad(lat)\n",
    "    declinationOfEarth = 23.45*np.sin(np.deg2rad(360.0*(283.0+dayOfYear)/365.0))\n",
    "    if -np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth)) <= -1.0:\n",
    "        return 24.0\n",
    "    elif -np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth)) >= 1.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        hourAngle = np.rad2deg(np.arccos(-np.tan(latInRad) * np.tan(np.deg2rad(declinationOfEarth))))\n",
    "        return 2.0*hourAngle/15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 9.58 s, total: 36.4 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_out = 'daylength'\n",
    "\n",
    "# determine day of the year for all sms frequency dates in previous data array\n",
    "doy = da['time'].dt.dayofyear\n",
    "# separate out unique values of doy and latitude\n",
    "doy_u = pd.unique(doy)\n",
    "lats = pd.unique(da['latitude'])\n",
    "\n",
    "# create array to store daylength calculation\n",
    "dl = np.empty((len(doy_u),len(lats)))\n",
    "# loop through unique doy and latitude to calculate daylength\n",
    "for i, dayofyear in enumerate(doy_u):\n",
    "    for j, latitude in enumerate(lats):\n",
    "        dl[i,j] = daylength(dayofyear, latitude)\n",
    "\n",
    "# create array to fill in daylength values for all dates\n",
    "dl_grid = np.empty((len(da['time']),len(da['latitude'])))\n",
    "\n",
    "# loop through daylength calculations and fill in grid array where doy matches\n",
    "for i,value in enumerate(doy_u):\n",
    "    idx = np.where(doy == value)\n",
    "    for j in idx:\n",
    "        dl_grid[j,:] = dl[i,:]\n",
    "        \n",
    "# create longitude dimension and repeat latitudinal values across dimension\n",
    "dl_grid = np.repeat(dl_grid[:,:, np.newaxis], len(da['longitude']), axis=2)\n",
    "\n",
    "# create new data array with daylength values\n",
    "da = xr.DataArray(dl_grid, coords = (da['time'], da['latitude'], da['longitude']))\n",
    "\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "\n",
    "# save daily output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out_daily + file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly output\n",
    "da.name = file_out\n",
    "da.to_netcdf(wrf_out + file_out + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eto90sum and cwd90sum\n",
    "Uses temp_array from temp90mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_speed_2m(ws, z):\n",
    "    \"\"\"\n",
    "    Convert wind speed measured at different heights above the soil\n",
    "    surface to wind speed at 2 m above the surface, assuming a short grass\n",
    "    surface.\n",
    "    Based on FAO equation 47 in Allen et al (1998).\n",
    "    :param ws: Measured wind speed [m s-1]\n",
    "    :param z: Height of wind measurement above ground surface [m]\n",
    "    :return: Wind speed at 2 m above the surface [m s-1]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return ws * (4.87 / math.log((67.8 * z) - 5.42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_svp(t):\n",
    "    \"\"\"\n",
    "    Estimate the slope of the saturation vapour pressure curve at a given\n",
    "    temperature.\n",
    "    Based on equation 13 in Allen et al (1998). If using in the Penman-Monteith\n",
    "    *t* should be the mean air temperature.\n",
    "    :param t: Air temperature [deg C]. Use mean air temperature for use in\n",
    "        Penman-Monteith.\n",
    "    :return: Saturation vapour pressure [kPa degC-1]\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    tmp = 4098 * (0.6108 * np.exp((17.27 * t) / (t + 237.3)))\n",
    "    return tmp / np.power((t + 237.3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psy_const(atmos_pres):\n",
    "    \"\"\"\n",
    "    Calculate the psychrometric constant.\n",
    "    This method assumes that the air is saturated with water vapour at the\n",
    "    minimum daily temperature. This assumption may not hold in arid areas.\n",
    "    Based on equation 8, page 95 in Allen et al (1998).\n",
    "    :param atmos_pres: Atmospheric pressure [kPa]. Can be estimated using\n",
    "        ``atm_pressure()``.\n",
    "    :return: Psychrometric constant [kPa degC-1].\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return 0.000665 * atmos_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fao56_penman_monteith(net_rad, t, ws, svp, avp, delta_svp, psy, shf=0.0):\n",
    "    \"\"\"\n",
    "    Estimate reference evapotranspiration (ETo) from a hypothetical\n",
    "    short grass reference surface using the FAO-56 Penman-Monteith equation.\n",
    "    Based on equation 6 in Allen et al (1998).\n",
    "    :param net_rad: Net radiation at crop surface [MJ m-2 day-1]. If\n",
    "        necessary this can be estimated using ``net_rad()``.\n",
    "    :param t: Air temperature at 2 m height [deg Kelvin].\n",
    "    :param ws: Wind speed at 2 m height [m s-1]. If not measured at 2m,\n",
    "        convert using ``wind_speed_at_2m()``.\n",
    "    :param svp: Saturation vapour pressure [kPa]. Can be estimated using\n",
    "        ``svp_from_t()''.\n",
    "    :param avp: Actual vapour pressure [kPa]. Can be estimated using a range\n",
    "        of functions with names beginning with 'avp_from'.\n",
    "    :param delta_svp: Slope of saturation vapour pressure curve [kPa degC-1].\n",
    "        Can be estimated using ``delta_svp()``.\n",
    "    :param psy: Psychrometric constant [kPa deg C]. Can be estimatred using\n",
    "        ``psy_const_of_psychrometer()`` or ``psy_const()``.\n",
    "    :param shf: Soil heat flux (G) [MJ m-2 day-1] (default is 0.0, which is\n",
    "        reasonable for a daily or 10-day time steps). For monthly time steps\n",
    "        *shf* can be estimated using ``monthly_soil_heat_flux()`` or\n",
    "        ``monthly_soil_heat_flux2()``.\n",
    "    :return: Reference evapotranspiration (ETo) from a hypothetical\n",
    "        grass reference surface [mm day-1].\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    a1 = (0.408 * (net_rad - shf) * delta_svp /\n",
    "          (delta_svp + (psy * (1 + 0.34 * ws))))\n",
    "    a2 = (900 * ws / t * (svp - avp) * psy /\n",
    "          (delta_svp + (psy * (1 + 0.34 * ws))))\n",
    "    return a1 + a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated winds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'temp_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_array' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set file in names\n",
    "aet_file_in = 'aet.nc'\n",
    "pres_file_in = 'psfc.nc'\n",
    "netrad_file_in = 'netrad.nc'\n",
    "ea_file_in = 'ea.nc'\n",
    "es_file_in = 'es.nc'\n",
    "\n",
    "# wind file inputs from charles processing\n",
    "dir_in = 'dly_winds/'\n",
    "wnd_file_in = '*mean*.nc'\n",
    "\n",
    "# output names\n",
    "ds_out = 'cwd_ds.nc'\n",
    "eto_file_out = 'eto90sum'\n",
    "cwd_file_out = 'cwd90sum'\n",
    "\n",
    "# create list of all mean daily wind wrf files\n",
    "wrf_list = sorted(list(Path(wrf_ch_path + dir_in).glob(wnd_file_in)))\n",
    "\n",
    "# open all files into a dataset\n",
    "ds = xr.open_mfdataset(wrf_list)\n",
    "\n",
    "# assign lat/lon coordinates as spatial dimensions and clean up\n",
    "ds['south_north'] = wrf_lats\n",
    "ds['west_east'] = wrf_lons\n",
    "ds = ds.rename({'south_north':'latitude', 'west_east':'longitude', 'times':'time'})\n",
    "ex_coords = ['XLAT','XLONG']\n",
    "ds = ds.drop(ex_coords)\n",
    "\n",
    "# apply land-sea mask\n",
    "ds = ds.where(land_mask, drop=True)\n",
    "\n",
    "# calculate wind speed using u and v components and drop components\n",
    "ds['wspd'] = (['time', 'latitude', 'longitude'], np.sqrt(ds['u10mean'].to_numpy()**2 + ds['v10mean'].to_numpy()**2))\n",
    "ds = ds.drop(['u10mean','v10mean'])\n",
    "\n",
    "# convert winds from 10m height to 2m height and save in dataset\n",
    "wspd2m = wind_speed_2m(ds['wspd'].to_numpy(), 10)\n",
    "ds['wspd'] = (['time', 'latitude', 'longitude'], wspd2m)\n",
    "print('calculated winds')\n",
    "\n",
    "# save temperature to dataset, \n",
    "# which was previously saved as temp_array from temp90mean section\n",
    "ds['temp'] = (['time', 'latitude', 'longitude'], temp_array)\n",
    "\n",
    "# convert temp_array to celcius to be used in delta_svp calculation\n",
    "temp_array = temp_array - 273.15\n",
    "\n",
    "# calculate slope of saturation vapor pressure curve at given temperature\n",
    "svp = delta_svp(temp_array)\n",
    "ds['svp'] = (['time', 'latitude', 'longitude'], svp)\n",
    "print('calculated svp')\n",
    "\n",
    "# read in daily pressure netcdf\n",
    "da = xr.open_dataarray(wrf_vars_path + pres_file_in)\n",
    "# resample and interpolate sporadic missing days\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "\n",
    "# calculate psychrometric constant at given pressure\n",
    "psy = psy_const(da.data)\n",
    "ds['psy'] = (['time', 'latitude', 'longitude'], psy)\n",
    "print('calculated psy')\n",
    "\n",
    "# read in daily netrad netcdf\n",
    "da = xr.open_dataarray(wrf_vars_path + netrad_file_in)\n",
    "# resample to fill missing days with nan\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "# feed data into dataset\n",
    "ds['netrad'] = (['time', 'latitude', 'longitude'], (da.data * 0.0864))\n",
    "print('done with netrad')\n",
    "\n",
    "# read in daily actual vapor pressure (ea) netcdf\n",
    "da = xr.open_dataarray(wrf_vars_path + ea_file_in)\n",
    "# resample to fill missing days with nan\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "# feed data into dataset\n",
    "ds['ea'] = (['time', 'latitude', 'longitude'], (da.data / 1000))\n",
    "print('done with ea')\n",
    "\n",
    "# read in daily saturation vapor pressure (es) netcdf\n",
    "da = xr.open_dataarray(wrf_vars_path + es_file_in)\n",
    "# resample to fill missing days with nan\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "# feed data into dataset\n",
    "ds['es'] = (['time', 'latitude', 'longitude'], (da.data / 1000))\n",
    "print('done with es')\n",
    "\n",
    "# calculate daily reference evapotranspiration using penman monteith equation and save in dataset\n",
    "eto1sum = fao56_penman_monteith(ds['netrad'].to_numpy(), ds['temp'].to_numpy(), ds['wspd'].to_numpy(), \\\n",
    "                                ds['es'].to_numpy(), ds['ea'].to_numpy(), ds['svp'].to_numpy(), ds['psy'].to_numpy(), shf=0.0)\n",
    "ds['eto'] = (['time', 'latitude', 'longitude'], eto1sum)\n",
    "print('done with eto')\n",
    "\n",
    "# read in daily actual evapotranspiration netcdf\n",
    "da = xr.open_dataarray(wrf_vars_path + aet_file_in)\n",
    "# resample and interpolate sporadic missing days\n",
    "da = da.resample(time='D').interpolate('quadratic')\n",
    "# apply land-sea mask\n",
    "da = da.where(land_mask, drop=True)\n",
    "# feed data into dataset\n",
    "ds['aet'] = (['time', 'latitude', 'longitude'], da.data)\n",
    "\n",
    "# calculate daily climatic water deficit\n",
    "ds['cwd'] = (['time', 'latitude', 'longitude'], (ds['eto'].to_numpy() - ds['aet'].to_numpy()))\n",
    "\n",
    "# save dataset as netcdf\n",
    "# ds.to_netcdf(wrf_out + ds_out)\n",
    "# print('saved dataset')\n",
    "\n",
    "# calculate 90-day sum for reference evapotranspiration\n",
    "da = ds['eto'].rolling(time=90, min_periods=85).sum()\n",
    "\n",
    "# save daily outputs\n",
    "da.name = eto_file_out\n",
    "#da.to_netcdf(wrf_out_daily + eto_file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly outputs\n",
    "#da.to_netcdf(wrf_out + eto_file_out + '.nc')\n",
    "print('saved eto')\n",
    "\n",
    "# calculate 90-day sum for climatic water deficit\n",
    "da = ds['cwd'].rolling(time=90, min_periods=85).sum()\n",
    "\n",
    "# save daily outputs\n",
    "da.name = cwd_file_out\n",
    "da.to_netcdf(wrf_out_daily + cwd_file_out + '_daily.nc')\n",
    "\n",
    "# resample to values on the 1st and the 15th\n",
    "da = da.resample(time='SMS').nearest()\n",
    "\n",
    "# save semi-monthly outputs\n",
    "da.to_netcdf(wrf_out + cwd_file_out + '.nc')\n",
    "print('saved cwd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyclivac)",
   "language": "python",
   "name": "pyclivac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
