{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7eddeb-a7a0-4b31-89ea-f730e83f4f71",
   "metadata": {},
   "source": [
    "# Conduct quantile mapping bias correction at each site, <br> testing different number of quantiles\n",
    "Last updated: Kevin Varga, 11/27/2024\n",
    "\n",
    "**Inputs:**\n",
    "* Chamise LFM observations\n",
    "* Chamise random forest model\n",
    "* Predictor variables at each LFM obs site for entire temporal domain\n",
    "\n",
    "**Outputs:**\n",
    "* Dataframe of observed, predicted, and corrected at each LFM observation site for each number of quantiles tested\n",
    "* Dataframe showing number of actual and interpolated observations, as well as initial and corrected MBE for each site/quantile\n",
    "* Time series plot of each site/quantile showing observed, predicted, and corrected\n",
    "* Dataframe summarizing MBE change at each site/quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2a4f44-83ea-4eac-9987-ada884005c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34075a6-618b-4078-812d-be904b00e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for LFM observations\n",
    "obs_path = '/home/sbarc/students/varga/nasa/ch1/data/lfm_obs/'\n",
    "# Path for random forest model\n",
    "rf_path = '/home/sbarc/students/varga/nasa/ch1/data/random_forest/'\n",
    "# Path for fuel specific predictor dataframes\n",
    "# Note that bias correction is only performed for chamise due to observation spatial coverage\n",
    "pred_path = '/home/sbarc/students/varga/nasa/ch1/data/bias_correction/site_predictors/'\n",
    "output_path = '/home/sbarc/students/varga/nasa/ch1/data/bias_correction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ee15e7-6b98-4093-ae77-38f3c0bb0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in LFM observations and clean up\n",
    "obs_df = pd.read_csv(obs_path + 'lfm_crop.csv')\n",
    "obs_df.drop(columns=['slope', 'aspect', 'elevation', 'gacc', 'category'], inplace=True)\n",
    "obs_df['date'] = pd.to_datetime(obs_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50232fbf-1c5f-4d13-a01a-45b8fb2e2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in random forest model and set up dataframe and variables for quantile mapping\n",
    "\n",
    "# Set fuel type\n",
    "fuel_type = 'chamise'\n",
    "# Read in fuel specific random forest model and predictor dataframe\n",
    "fuel_rf = joblib.load(rf_path + fuel_type + '.rf.joblib')\n",
    "fuel_df = pd.read_csv(pred_path + fuel_type + '.csv', index_col=[0,1], parse_dates=True, infer_datetime_format=True)\n",
    "# Set up dataframe to plug in observed, predicted, and corrected values\n",
    "predict_df = pd.DataFrame(index=fuel_df.index, columns=['observed', 'predicted', 'corrected'])\n",
    "# Drop latitude and longitude, as they are not predictors\n",
    "fuel_df.drop(columns = ['latitude', 'longitude'], inplace=True)\n",
    "# Save LFM observation site names\n",
    "sites = pd.unique(predict_df.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ca2bc0-945c-4189-85ef-e05c23a171d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "CPU times: user 8min 44s, sys: 1min 11s, total: 9min 56s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create array of quantile values to test\n",
    "all_quantiles = np.arange(10,110,10)\n",
    "\n",
    "# Create dataframe to store stats summary\n",
    "stat_sum_df = pd.DataFrame(index=sites, columns=all_quantiles)\n",
    "\n",
    "for n_quantiles in all_quantiles:\n",
    "    print(n_quantiles)\n",
    "    \n",
    "    # Create dataframe to store site specific stats for each number of quantiles\n",
    "    stats_df = pd.DataFrame(index=sites, columns=['n_obs','n_obs_int','MBE','Corrected','Change'])\n",
    "\n",
    "    for site_name in sites:\n",
    "        # Extract predictors for individual sites\n",
    "        site_predictors = fuel_df.loc[site_name]\n",
    "        # Standardize predictors\n",
    "        scaler = StandardScaler().fit(site_predictors)\n",
    "        predictors_scaled = pd.DataFrame(scaler.transform(site_predictors), \n",
    "                                         index=site_predictors.index, \n",
    "                                         columns=site_predictors.columns.values)\n",
    "        # Run the random forest\n",
    "        predicted_lfm = fuel_rf.predict(predictors_scaled)\n",
    "\n",
    "        # Plug in predicted values to df\n",
    "        predict_df.loc[site_name, 'predicted'] = predicted_lfm\n",
    "\n",
    "        # Extract observations for each site\n",
    "        site_obs = obs_df.loc[(obs_df['site'] == site_name) & (obs_df['fuel'] == fuel_type)]\n",
    "        site_obs.set_index('date', drop=True, inplace=True)\n",
    "\n",
    "        # Reindex and interpolate observations to match temporal frequency of model output\n",
    "        # Limit interpolation in either direction to two time steps\n",
    "        # Allowing interpolation helps bias correction by extrapolating values\n",
    "        obs_int = site_obs['percent'].reindex(site_obs.index.union(predict_df.loc[site_name].index)) \\\n",
    "                                     .interpolate(method='quadratic', limit=2, limit_direction='both') \\\n",
    "                                     .reindex(predict_df.loc[site_name].index)\n",
    "\n",
    "        # Plug in number of observations and number of interpolated observations to stats_df\n",
    "        stats_df.loc[site_name, 'n_obs'] = len(site_obs['percent'])\n",
    "        stats_df.loc[site_name, 'n_obs_int'] = len(obs_int.dropna())\n",
    "\n",
    "        # Plug in interpolated observation values to df\n",
    "        predict_df.loc[site_name, 'observed'] = obs_int.values\n",
    "\n",
    "        # Extract interpolated observed and model predicted values during the observation temporal domain\n",
    "        obs = predict_df.loc[site_name, 'observed'][site_obs.index[0]:site_obs.index[-1]]\n",
    "        obs = obs.dropna()\n",
    "        obs_idx = obs.index\n",
    "        compare = predict_df.loc[site_name, 'predicted'][obs_idx]\n",
    "        predicted = predict_df.loc[site_name, 'predicted']\n",
    "\n",
    "        # Calculate and plug in starting MBE using interpolated observations\n",
    "        starting_mbe = round(np.mean(compare - obs), 2)\n",
    "        stats_df.loc[site_name, 'MBE'] = starting_mbe\n",
    "\n",
    "        # Perform quantile mapping bias correction\n",
    "\n",
    "        # Calculate quantiles\n",
    "        quantiles = np.linspace(0, 1, n_quantiles+1)  # Adjust the quantiles range as needed\n",
    "\n",
    "        # Sort observed and modeled\n",
    "        observed = np.percentile(obs.values, quantiles * 100)\n",
    "        modeled = np.percentile(compare.values, quantiles * 100)\n",
    "        # Calculate the difference between the sorted values\n",
    "        difference = [x - y for x, y in zip(observed, modeled)]\n",
    "\n",
    "        # Calculate quantile values for each model output\n",
    "        q_values = np.percentile(predicted.values, quantiles * 100)\n",
    "        # Create dataframes for mapping\n",
    "        mapping_df = pd.DataFrame({'quantiles': quantiles, 'q_values': q_values, 'correction': difference})\n",
    "        predicted = predicted.to_frame(name='predicted')\n",
    "\n",
    "        # Assign mapped q-values to each modeled value\n",
    "        predicted.loc[:, 'mapped_q_values'] = pd.qcut(predicted['predicted'], \n",
    "                                                      n_quantiles, \n",
    "                                                      labels=mapping_df['q_values'][1:])\n",
    "\n",
    "        # Map q-values to the associated correction\n",
    "        mappings = dict(zip(mapping_df['q_values'].values, mapping_df['correction'].values))\n",
    "        predicted.loc[:, 'correction'] = predicted['mapped_q_values'].map(mappings)\n",
    "        # Plug in corrected values by adding the correction factor to the predicted value\n",
    "        predicted.loc[:, 'corrected'] = predicted['predicted'].astype(float) + predicted['correction'].astype(float)\n",
    "        # Plug in corrected values to larger df\n",
    "        predict_df.loc[site_name, 'corrected'][predicted.index] = predicted['corrected']\n",
    "\n",
    "        # Calculate and plug in final corrected mbe\n",
    "        final_mbe = round(np.mean(predict_df.loc[site_name, 'corrected'][obs.index] - obs), 2)\n",
    "        #print(site_name + ' MBE: ' + str(final_mbe) + ' = corrected MBE')\n",
    "        stats_df.loc[site_name, 'Corrected'] = final_mbe\n",
    "        stats_df.loc[site_name, 'Change'] = round(abs(final_mbe) - abs(starting_mbe), 2)\n",
    "\n",
    "        # Plot and save the corrected time series within the observed temporal domain\n",
    "        predict_df.loc[site_name, 'observed'][site_obs.index[0]:site_obs.index[-1]].plot(figsize=(20,10), legend=True, grid=True, lw=2, fontsize=16);\n",
    "        predict_df.loc[site_name, 'predicted'][site_obs.index[0]:site_obs.index[-1]].plot(figsize=(20,10), legend=True, grid=True, lw=2, fontsize=16);\n",
    "        predict_df.loc[site_name, 'corrected'][site_obs.index[0]:site_obs.index[-1]].plot(figsize=(20,10), legend=True, grid=True, lw=2, fontsize=16);\n",
    "        plt.title(site_name.replace('_', ' ').title() + ' -- Model MBE: ' + str(starting_mbe) + ' -- Corrected MBE: ' + str(final_mbe), fontsize=16);\n",
    "        plt.legend(fontsize=16);\n",
    "        plt.ylabel('LFM %', fontsize=16);\n",
    "        plt.xlabel('');\n",
    "        plt.savefig(output_path + fuel_type + '/' + str(n_quantiles) + '_' + site_name + '.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Save the post bias correction MBE change for each site for each quantile value\n",
    "    stat_sum_df.loc[:, n_quantiles] = stats_df.loc[:, 'Change'].values\n",
    "    # Save stats and model output dataframes for each quantile value\n",
    "    stats_df.to_csv(output_path + fuel_type + '/' + str(n_quantiles) + '_stats.csv', index_label='site')\n",
    "    predict_df.to_csv(output_path + fuel_type + '/' + str(n_quantiles) + '_model_output.csv', index_label=['site','date'])\n",
    "\n",
    "# Calculate means and add it as a row at the bottom of stats summary dataframe\n",
    "means = [stat_sum_df.loc[:, all_quantiles[x]].mean() for x in np.arange(0,len(all_quantiles))]\n",
    "stat_sum_df.loc['mean'] = means\n",
    "# Save stats summary dataframe\n",
    "stat_sum_df.to_csv(output_path + fuel_type + '/q_stats_summary.csv', index_label='site')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyclivac)",
   "language": "python",
   "name": "pyclivac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
